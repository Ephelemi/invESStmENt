{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-10 17:33:13.484526: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-10 17:33:13.553889: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-10 17:33:13.555193: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-10 17:33:14.583266: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English spacy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Stop word list from NLTK\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "stopword_list.append('@user')\n",
    "stopword_list.append('url')\n",
    "# Punctuation list from string\n",
    "puncts = string.punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kontraktionen exandieren -> Negation\n",
    "def decontract_phrase(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"shan\\'t\", \"shall not\", phrase)\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not \", phrase)\n",
    "    phrase = re.sub(r\"\\'re \", \" are \", phrase)\n",
    "    phrase = re.sub(r\"\\'s \", \" is \", phrase)\n",
    "    phrase = re.sub(r\"\\'d \", \" would \", phrase)\n",
    "    phrase = re.sub(r\"\\'ll \", \" will \", phrase)\n",
    "    phrase = re.sub(r\"\\'t \", \" not \", phrase)\n",
    "    phrase = re.sub(r\"\\'ve \", \" have \", phrase)\n",
    "    phrase = re.sub(r\"\\'m \", \" am \", phrase)\n",
    "    \n",
    "    phrase = re.sub(r'\\s+', ' ', phrase)\n",
    "\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma(review):\n",
    "    doc = nlp(review)\n",
    "    lemma_text = ' '.join([token.lemma_ for token in doc])\n",
    "    \n",
    "    return lemma_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'USER MP praise innovative publicsector think week Britain prosper 21st century embrace digital economy'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_pipeline(review):\n",
    "    # Kontraktionen expandieren\n",
    "    review = decontract_phrase(review)\n",
    "    # Tokenisierung und Lemmatisierung\n",
    "    review = get_lemma(review)    \n",
    "    # Stopwords\n",
    "    review = ' '.join([token for token in review.split() if token.lower() not in stopword_list])\n",
    "    # Satzzeichen\n",
    "    review = ''.join([character for character in review if character not in puncts])\n",
    "    # Remove multiple whitespaces\n",
    "    review = re.sub(r'^\\s+', '', review)\n",
    "    review = re.sub(r' +', ' ', review)\n",
    "    review = re.sub(r'\\s+$', '', review)\n",
    "    \n",
    "    return review\n",
    "\n",
    "test = \".@USER @USER and @USER MP @USER praises the 'innovative #publicsector thinking' of @USER this week in @USER  If Britain is to prosper in the 21st century, it is through embracing the #digital economy URL URL\"\n",
    "preprocess_pipeline(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>. @USER @USER @USER @USER Fake conservatives a...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER @USER You are sick in the head. This man...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ðŸ›‘ Truthfeed News ðŸ›‘ ðŸ‘‰ 'Schumer and Feinstein Go...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER @USER best lead @USER &amp;amp; @USER most u...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER @USER The liberals can never handle the ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Task\n",
       "0  . @USER @USER @USER @USER Fake conservatives a...  NOT\n",
       "1  @USER @USER You are sick in the head. This man...  OFF\n",
       "2  ðŸ›‘ Truthfeed News ðŸ›‘ ðŸ‘‰ 'Schumer and Feinstein Go...  NOT\n",
       "3  @USER @USER best lead @USER &amp; @USER most u...  NOT\n",
       "4  @USER @USER The liberals can never handle the ...  OFF"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./Praktikum_OLID_dev.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2620 entries, 0 to 2619\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    2620 non-null   object\n",
      " 1   Task    2620 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 41.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Are all columns defined?\n",
    "# Non-Null Count shows how many rows for each column are well-defined\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2620 entries, 0 to 2619\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Text          2620 non-null   object\n",
      " 1   Task          2620 non-null   object\n",
      " 2   Preprocessed  2620 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 61.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset['Preprocessed'] = dataset['Text'].apply(preprocess_pipeline)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Task</th>\n",
       "      <th>Preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>. @USER @USER @USER @USER Fake conservatives a...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>fake conservative fake outrage budget betrayal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER @USER You are sick in the head. This man...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>sick head man lose daughter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ðŸ›‘ Truthfeed News ðŸ›‘ ðŸ‘‰ 'Schumer and Feinstein Go...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>ðŸ›‘ Truthfeed News ðŸ›‘ ðŸ‘‰ Schumer Feinstein Go HYST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER @USER best lead @USER &amp;amp; @USER most u...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>good lead amp underrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER @USER The liberals can never handle the ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>liberal never handle truth truth make head ðŸ’¥ ðŸ’¥...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Task   \n",
       "0  . @USER @USER @USER @USER Fake conservatives a...  NOT  \\\n",
       "1  @USER @USER You are sick in the head. This man...  OFF   \n",
       "2  ðŸ›‘ Truthfeed News ðŸ›‘ ðŸ‘‰ 'Schumer and Feinstein Go...  NOT   \n",
       "3  @USER @USER best lead @USER &amp; @USER most u...  NOT   \n",
       "4  @USER @USER The liberals can never handle the ...  OFF   \n",
       "\n",
       "                                        Preprocessed  \n",
       "0     fake conservative fake outrage budget betrayal  \n",
       "1                        sick head man lose daughter  \n",
       "2  ðŸ›‘ Truthfeed News ðŸ›‘ ðŸ‘‰ Schumer Feinstein Go HYST...  \n",
       "3                            good lead amp underrate  \n",
       "4  liberal never handle truth truth make head ðŸ’¥ ðŸ’¥...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2620, 6598)\n"
     ]
    }
   ],
   "source": [
    "cnt_vec = CountVectorizer()\n",
    "X_cnt = cnt_vec.fit_transform(dataset['Preprocessed'])\n",
    "print(X_cnt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['char_count'] = dataset['Text'].apply(len)\n",
    "dataset['word_count'] = dataset['Text'].apply(lambda x: len(x.split()))\n",
    "dataset['Density'] = dataset['char_count'] / (dataset['word_count']+1)\n",
    "dataset['punctuation_count'] = dataset['Text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation)))\n",
    "dataset['Punct_Count_Ratio'] = dataset['punctuation_count'] / dataset['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Task</th>\n",
       "      <th>Preprocessed</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>Punct_Count_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>. @USER @USER @USER @USER Fake conservatives a...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>fake conservative fake outrage budget betrayal</td>\n",
       "      <td>100</td>\n",
       "      <td>17</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>5</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER @USER You are sick in the head. This man...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>sick head man lose daughter</td>\n",
       "      <td>65</td>\n",
       "      <td>13</td>\n",
       "      <td>4.642857</td>\n",
       "      <td>4</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ðŸ›‘ Truthfeed News ðŸ›‘ ðŸ‘‰ 'Schumer and Feinstein Go...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>ðŸ›‘ Truthfeed News ðŸ›‘ ðŸ‘‰ Schumer Feinstein Go HYST...</td>\n",
       "      <td>134</td>\n",
       "      <td>21</td>\n",
       "      <td>6.090909</td>\n",
       "      <td>5</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER @USER best lead @USER &amp;amp; @USER most u...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>good lead amp underrate</td>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER @USER The liberals can never handle the ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>liberal never handle truth truth make head ðŸ’¥ ðŸ’¥...</td>\n",
       "      <td>90</td>\n",
       "      <td>15</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Task   \n",
       "0  . @USER @USER @USER @USER Fake conservatives a...  NOT  \\\n",
       "1  @USER @USER You are sick in the head. This man...  OFF   \n",
       "2  ðŸ›‘ Truthfeed News ðŸ›‘ ðŸ‘‰ 'Schumer and Feinstein Go...  NOT   \n",
       "3  @USER @USER best lead @USER &amp; @USER most u...  NOT   \n",
       "4  @USER @USER The liberals can never handle the ...  OFF   \n",
       "\n",
       "                                        Preprocessed  char_count  word_count   \n",
       "0     fake conservative fake outrage budget betrayal         100          17  \\\n",
       "1                        sick head man lose daughter          65          13   \n",
       "2  ðŸ›‘ Truthfeed News ðŸ›‘ ðŸ‘‰ Schumer Feinstein Go HYST...         134          21   \n",
       "3                            good lead amp underrate          55           9   \n",
       "4  liberal never handle truth truth make head ðŸ’¥ ðŸ’¥...          90          15   \n",
       "\n",
       "    Density  punctuation_count  Punct_Count_Ratio  \n",
       "0  5.555556                  5           0.294118  \n",
       "1  4.642857                  4           0.307692  \n",
       "2  6.090909                  5           0.238095  \n",
       "3  5.500000                  6           0.666667  \n",
       "4  5.625000                  5           0.333333  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2620, 6600)\n"
     ]
    }
   ],
   "source": [
    "X_dense = X_cnt.toarray()\n",
    "\n",
    "X_ling = np.vstack((dataset['Density'], \n",
    "                    dataset['Punct_Count_Ratio'])).T\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_ling_scale = scaler.fit_transform(X_ling)\n",
    "X = np.hstack((X_dense, X_ling_scale))\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2620,)\n",
      "[1 0 0 1 1 1 1 0 1 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 1 1\n",
      " 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Encode Labels\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(dataset['Task'])\n",
    "\n",
    "print(y.shape)\n",
    "print(y[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_range = np.logspace(-2, 10, 13)\n",
    "# gamma_range = np.logspace(-9, 3, 13)\n",
    "# param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "# \"average\": [True, False],\n",
    "\n",
    "param_grid = {\n",
    "    \"l1_ratio\": np.linspace(0, 1, num=10),\n",
    "    \"alpha\": np.logspace(-9, 3, 13),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 130 candidates, totalling 1300 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=SGDClassifier(),\n",
       "             param_grid={&#x27;alpha&#x27;: array([1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02,\n",
       "       1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;l1_ratio&#x27;: array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
       "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=SGDClassifier(),\n",
       "             param_grid={&#x27;alpha&#x27;: array([1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02,\n",
       "       1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;l1_ratio&#x27;: array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
       "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SGDClassifier(),\n",
       "             param_grid={'alpha': array([1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02,\n",
       "       1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'l1_ratio': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
       "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now create a GridSearchCV object and fit it to the data\n",
    "model = linear_model.SGDClassifier()\n",
    "search = GridSearchCV(estimator=model, cv=10,\n",
    "                      param_grid=param_grid,\n",
    "                      verbose=1)\n",
    "\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('The best parameters are {0} with a score of {1:0.2f}'.format(search.best_params_, search.best_score_))\n",
    "# print(search.best_params_.get('C'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7481\n",
      "Precision 0.646\n",
      "Recall 0.4424\n",
      "F1 0.5252\n"
     ]
    }
   ],
   "source": [
    "# Define model with optimized hyper-parameter\n",
    "# average=search.best_params_.get('average'), \n",
    "opt_model = linear_model.SGDClassifier(l1_ratio=search.best_params_.get('l1_ratio'),\n",
    "                                       alpha=search.best_params_.get('alpha'), penalty='elasticnet', fit_intercept=False)\n",
    "# Fit model on training data\n",
    "opt_model.fit(X_train, y_train)\n",
    "# Predict test set with optimized model\n",
    "y_opt = opt_model.predict(X_test)\n",
    "# Evaluate model\n",
    "accuracy = round(accuracy_score(y_test, y_opt), 4)\n",
    "precision = round(precision_score(y_test, y_opt), 4)\n",
    "recall = round(recall_score(y_test, y_opt), 4)\n",
    "f1 = round(f1_score(y_test, y_opt), 4)\n",
    "print('Accuracy {}\\nPrecision {}\\nRecall {}\\nF1 {}'.format(accuracy, precision, recall, f1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
