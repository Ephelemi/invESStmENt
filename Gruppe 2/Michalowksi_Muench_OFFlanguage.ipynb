{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from cleantext import clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English spacy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Stop word list from NLTK\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "stopword_list.append('@user')\n",
    "stopword_list.append('url')\n",
    "# Punctuation list from string\n",
    "puncts = string.punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kontraktionen exandieren -> Negation\n",
    "def decontract_phrase(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"shan\\'t\", \"shall not\", phrase)\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not \", phrase)\n",
    "    phrase = re.sub(r\"\\'re \", \" are \", phrase)\n",
    "    phrase = re.sub(r\"\\'s \", \" is \", phrase)\n",
    "    phrase = re.sub(r\"\\'d \", \" would \", phrase)\n",
    "    phrase = re.sub(r\"\\'ll \", \" will \", phrase)\n",
    "    phrase = re.sub(r\"\\'t \", \" not \", phrase)\n",
    "    phrase = re.sub(r\"\\'ve \", \" have \", phrase)\n",
    "    phrase = re.sub(r\"\\'m \", \" am \", phrase)\n",
    "    \n",
    "    phrase = re.sub(r'\\s+', ' ', phrase)\n",
    "\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma(review):\n",
    "    doc = nlp(review)\n",
    "    lemma_text = ' '.join([token.lemma_ for token in doc])\n",
    "    \n",
    "    return lemma_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'USER MP praise innovative publicsector think week Britain prosper 21st century embrace digital economy'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_pipeline(review):\n",
    "    # Kontraktionen expandieren\n",
    "    review = decontract_phrase(review)\n",
    "    # Tokenisierung und Lemmatisierung\n",
    "    review = get_lemma(review)    \n",
    "    # Stopwords\n",
    "    review = ' '.join([token for token in review.split() if token.lower() not in stopword_list])\n",
    "    # Satzzeichen\n",
    "    review = ''.join([character for character in review if character not in puncts])\n",
    "    # Remove multiple whitespaces\n",
    "    review = re.sub(r'^\\s+', '', review)\n",
    "    review = re.sub(r' +', ' ', review)\n",
    "    review = re.sub(r'\\s+$', '', review)\n",
    "    # remove Emojis\n",
    "    # review = clean(review, no_emoji=True)\n",
    "    \n",
    "    return review\n",
    "\n",
    "test = \".@USER @USER and @USER MP @USER praises the 'innovative #publicsector thinking' of @USER this week in @USER  If Britain is to prosper in the 21st century, it is through embracing the #digital economy URL URL\"\n",
    "test2 = \"@USER She is beyond famous. She is Lalisa Manoban ðŸ˜Ž URL\"\n",
    "preprocess_pipeline(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER bakkt is doing what an ETF would have do...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER I can't ðŸ˜­ðŸ˜­ he is already 26</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@USER he is a psychic ainâ€™t he</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.@USER @USER and @USER MP @USER praises the 'i...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER @USER [Eric opens the door and runs to t...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Task\n",
       "0  @USER bakkt is doing what an ETF would have do...  OFF\n",
       "1                  @USER I can't ðŸ˜­ðŸ˜­ he is already 26  NOT\n",
       "2                     @USER he is a psychic ainâ€™t he  NOT\n",
       "3  .@USER @USER and @USER MP @USER praises the 'i...  NOT\n",
       "4  @USER @USER [Eric opens the door and runs to t...  OFF"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./Praktikum_OLID_train.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10481 entries, 0 to 10480\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    10481 non-null  object\n",
      " 1   Task    10481 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 163.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Are all columns defined?\n",
    "# Non-Null Count shows how many rows for each column are well-defined\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10481 entries, 0 to 10480\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Text          10481 non-null  object\n",
      " 1   Task          10481 non-null  object\n",
      " 2   Preprocessed  10481 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 245.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset['Preprocessed'] = dataset['Text'].apply(preprocess_pipeline)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Task</th>\n",
       "      <th>Preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER bakkt is doing what an ETF would have do...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>bakkt etf would not call etf FUKEN CUUUUUKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER I can't ðŸ˜­ðŸ˜­ he is already 26</td>\n",
       "      <td>NOT</td>\n",
       "      <td>not ðŸ˜­ ðŸ˜­ already 26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@USER he is a psychic ainâ€™t he</td>\n",
       "      <td>NOT</td>\n",
       "      <td>psychic ai not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.@USER @USER and @USER MP @USER praises the 'i...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>USER MP praise innovative publicsector think w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER @USER [Eric opens the door and runs to t...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>Eric open door run couch fuck yeah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Task   \n",
       "0  @USER bakkt is doing what an ETF would have do...  OFF  \\\n",
       "1                  @USER I can't ðŸ˜­ðŸ˜­ he is already 26  NOT   \n",
       "2                     @USER he is a psychic ainâ€™t he  NOT   \n",
       "3  .@USER @USER and @USER MP @USER praises the 'i...  NOT   \n",
       "4  @USER @USER [Eric opens the door and runs to t...  OFF   \n",
       "\n",
       "                                        Preprocessed  \n",
       "0        bakkt etf would not call etf FUKEN CUUUUUKS  \n",
       "1                                 not ðŸ˜­ ðŸ˜­ already 26  \n",
       "2                                     psychic ai not  \n",
       "3  USER MP praise innovative publicsector think w...  \n",
       "4                 Eric open door run couch fuck yeah  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10481, 14992)\n"
     ]
    }
   ],
   "source": [
    "cnt_vec = CountVectorizer()\n",
    "X_cnt = cnt_vec.fit_transform(dataset['Preprocessed'])\n",
    "print(X_cnt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['char_count'] = dataset['Text'].apply(len)\n",
    "dataset['word_count'] = dataset['Text'].apply(lambda x: len(x.split()))\n",
    "dataset['Density'] = dataset['char_count'] / (dataset['word_count']+1)\n",
    "dataset['punctuation_count'] = dataset['Text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation)))\n",
    "dataset['Punct_Count_Ratio'] = dataset['punctuation_count'] / dataset['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Task</th>\n",
       "      <th>Preprocessed</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>Punct_Count_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER bakkt is doing what an ETF would have do...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>bakkt etf would not call etf FUKEN CUUUUUKS</td>\n",
       "      <td>103</td>\n",
       "      <td>20</td>\n",
       "      <td>4.904762</td>\n",
       "      <td>5</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER I can't ðŸ˜­ðŸ˜­ he is already 26</td>\n",
       "      <td>NOT</td>\n",
       "      <td>not ðŸ˜­ ðŸ˜­ already 26</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@USER he is a psychic ainâ€™t he</td>\n",
       "      <td>NOT</td>\n",
       "      <td>psychic ai not</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.@USER @USER and @USER MP @USER praises the 'i...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>USER MP praise innovative publicsector think w...</td>\n",
       "      <td>211</td>\n",
       "      <td>36</td>\n",
       "      <td>5.702703</td>\n",
       "      <td>13</td>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER @USER [Eric opens the door and runs to t...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>Eric open door run couch fuck yeah</td>\n",
       "      <td>67</td>\n",
       "      <td>13</td>\n",
       "      <td>4.785714</td>\n",
       "      <td>6</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Task   \n",
       "0  @USER bakkt is doing what an ETF would have do...  OFF  \\\n",
       "1                  @USER I can't ðŸ˜­ðŸ˜­ he is already 26  NOT   \n",
       "2                     @USER he is a psychic ainâ€™t he  NOT   \n",
       "3  .@USER @USER and @USER MP @USER praises the 'i...  NOT   \n",
       "4  @USER @USER [Eric opens the door and runs to t...  OFF   \n",
       "\n",
       "                                        Preprocessed  char_count  word_count   \n",
       "0        bakkt etf would not call etf FUKEN CUUUUUKS         103          20  \\\n",
       "1                                 not ðŸ˜­ ðŸ˜­ already 26          33           8   \n",
       "2                                     psychic ai not          30           7   \n",
       "3  USER MP praise innovative publicsector think w...         211          36   \n",
       "4                 Eric open door run couch fuck yeah          67          13   \n",
       "\n",
       "    Density  punctuation_count  Punct_Count_Ratio  \n",
       "0  4.904762                  5           0.250000  \n",
       "1  3.666667                  2           0.250000  \n",
       "2  3.750000                  1           0.142857  \n",
       "3  5.702703                 13           0.361111  \n",
       "4  4.785714                  6           0.461538  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10481, 14994)\n"
     ]
    }
   ],
   "source": [
    "X_dense = X_cnt.toarray()\n",
    "\n",
    "X_ling = np.vstack((dataset['Density'], \n",
    "                    dataset['Punct_Count_Ratio'])).T\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_ling_scale = scaler.fit_transform(X_ling)\n",
    "X = np.hstack((X_dense, X_ling_scale))\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10481,)\n",
      "[0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 0 0 1\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Encode Labels\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(dataset['Task'])\n",
    "\n",
    "print(y.shape)\n",
    "print(y[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 done\n",
      "[1 1 1 ... 0 1 1]\n",
      "Fold 2 done\n",
      "[0 1 0 ... 1 1 0]\n",
      "Fold 3 done\n",
      "[1 1 0 ... 1 1 1]\n",
      "Fold 4 done\n",
      "[0 0 0 ... 1 0 0]\n",
      "Fold 5 done\n",
      "[0 0 0 ... 0 1 0]\n",
      "Fold 6 done\n",
      "[1 1 0 ... 0 0 0]\n",
      "Fold 7 done\n",
      "[0 0 0 ... 1 1 0]\n",
      "Fold 8 done\n",
      "[0 0 0 ... 0 0 0]\n",
      "Fold 9 done\n",
      "[0 0 1 ... 0 0 0]\n",
      "Fold 10 done\n",
      "[0 0 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "evaluation_list = list()\n",
    "\n",
    "for fold, [train, test] in enumerate(kfold.split(X, y)):\n",
    "    # Get test data\n",
    "    X_test = X[test]\n",
    "    y_test = y[test]\n",
    "    # Define model\n",
    "    model = linear_model.SGDClassifier()\n",
    "    # model = svm.LinearSVC()\n",
    "    # model = linear_model.SGDClassifier(loss='perceptron')\n",
    "    # Fit model\n",
    "    model.fit(X[train], y[train])\n",
    "    # Predict test set with model\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Evaluate model\n",
    "    accuracy = round(accuracy_score(y_test, y_pred), 4)\n",
    "    precision = round(precision_score(y_test, y_pred), 4)\n",
    "    recall = round(recall_score(y_test, y_pred), 4)\n",
    "    f1 = round(f1_score(y_test, y_pred), 4)\n",
    "    # Append results\n",
    "    evaluation_list.append([fold+1, accuracy, precision, recall, f1])\n",
    "    print('Fold', fold+1, 'done')\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Fold  Accuracy  Precision  Recall  F1-Score\n",
      "0     1    0.7407     0.6149  0.5723    0.5928\n",
      "1     2    0.7395     0.6174  0.5549    0.5845\n",
      "2     3    0.7338     0.6044  0.5607    0.5817\n",
      "3     4    0.7500     0.6498  0.5217    0.5788\n",
      "4     5    0.7281     0.5932  0.5536    0.5727\n",
      "5     6    0.7385     0.6282  0.5043    0.5595\n",
      "6     7    0.7214     0.5826  0.5420    0.5616\n",
      "7     8    0.7099     0.5623  0.5362    0.5490\n",
      "8     9    0.7433     0.6226  0.5594    0.5893\n",
      "9    10    0.7519     0.6471  0.5420    0.5899\n",
      "10  AVG    0.7357     0.6123  0.5447    0.5760\n"
     ]
    }
   ],
   "source": [
    "# Export Results\n",
    "acc_avg = [i[1] for i in evaluation_list]\n",
    "prec_avg = [i[2] for i in evaluation_list]\n",
    "recall_avg = [i[3] for i in evaluation_list]\n",
    "f1_avg = [i[4] for i in evaluation_list]\n",
    "\n",
    "evaluation_list.append(['AVG',\n",
    "                        round(np.mean(acc_avg), 4),\n",
    "                        round(np.mean(prec_avg), 4),\n",
    "                        round(np.mean(recall_avg), 4),\n",
    "                        round(np.mean(f1_avg), 4)])\n",
    "\n",
    "evaluation_df = pd.DataFrame(evaluation_list, columns=['Fold', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])\n",
    "#evaluation_df.to_csv('./Wine_SVM_evaluation.csv', index=False, sep=';')\n",
    "print(evaluation_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
